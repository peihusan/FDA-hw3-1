{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FDA-hw3-1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOL3vcEkWZOZZ0GwNHGtgfv"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bFW_7uDs8jkh","colab_type":"text"},"source":["## Implement 3 classifiers to predict the stock movement\n","* Logistic Regression\n","* Neural Network\n","* SVM\n"]},{"cell_type":"code","metadata":{"id":"SxlWtTdp8tG4","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","\n","\n","class LogisticRegression(nn.Module):\n","  def __init__(self, size):\n","    super(LogisticRegression, self).__init__()\n","    self.size = size\n","    self.linear = nn.Linear(size, 1)\n","\n","  def forward(self, batch_x):\n","    y = self.linear(batch_x)\n","    return torch.sigmoid(y).round()\n","\n","class SVM(nn.Module):\n","  def __init__(self, size):\n","    super(SVM, self).__init__()\n","    self.size = size\n","    self.linear = nn.Linear(size, 1)\n","  def forward(self, batch_x):\n","    return self.linear(batch_x).round()\n","\n","class NeuralNetwork(nn.Module):\n","  def __init__(self, size):\n","    super(NeuralNetwork, self).__init__()\n","    self.size = size\n","    self.layer1 = nn.Sequential(\n","        nn.Linear(size, 32),\n","        nn.ReLU()\n","    )\n","    self.layer2 = nn.Sequential(\n","        nn.Linear(32, 8),\n","        nn.Tanh()\n","    )\n","    self.layer3 = nn.Linear(8, 1)\n","    \n","  def forward(self, batch_x):\n","    h1 = self.layer1(batch_x)\n","    h2 = self.layer2(h1)\n","    y = self.layer3(h2)\n","\n","    return torch.sigmoid(y).round()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hVqYuAtBrHc8","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset\n","\n","class StockDataset(Dataset):\n","  def __init__(self, x, y):\n","    self.x = x\n","    self.y = y\n","  def __len__(self): return len(self.x)\n","  def __getitem__(self, i): return self.x[i], self.y[i]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gzxNqoPokOE9","colab_type":"text"},"source":["#### I'll try to predict the Close Price movement based on the previous several prices"]},{"cell_type":"code","metadata":{"id":"_z9khVnrRm_D","colab_type":"code","outputId":"b5e3b8b7-97c3-47a2-f7ad-752af0691b5f","executionInfo":{"status":"ok","timestamp":1590508150188,"user_tz":-480,"elapsed":153485,"user":{"displayName":"F74056132洪培軒","photoUrl":"","userId":"18180719323566537567"}},"colab":{"base_uri":"https://localhost:8080/","height":626}},"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","NUM_FETCH = 5 # Number of days to fetch for next prediction\n","NUM_BATCH = 20\n","NUM_EPOCH = 500 # Number of epochs to train\n","\n","def preprocess_x(data, num_fetch):\n","  ret = []\n","  for n, c in data.iteritems():\n","    for i in range(len(c)-num_fetch):\n","      try:\n","        ret[i]\n","      except:\n","        ret.append(np.array([]))\n","        \n","      ret[i] = np.concatenate((ret[i], c[i:i+num_fetch]))\n","  return np.array(ret)\n","\n","def preprocess_data(data):\n","  ret = pd.DataFrame()\n","  for n, c in data.iteritems():\n","    if n == \"Close Price\":      \n","      x = np.array([int(c[i]>c[i-1]) for i in range(1, len(c))])\n","      ret[n] = x\n","  \n","  return ret\n","\n","def collate_fn(batch):\n","  x_list = []\n","  y_list = []\n","  for x, y in batch:\n","    x_list.append([x])\n","    y_list.append([y])\n","  return [torch.tensor(x_list).float(), torch.tensor(y_list).float()]\n","\n","\n","def train(model, criterion, optimizer):\n","  global dataloader, test_dataloader\n","  for epoch in range(NUM_EPOCH):\n","    model.train()\n","    if epoch % 100 == 0: print(f'Epoch {epoch}==========================')\n","    for batch_x, batch_y in dataloader:\n","      pred_y = model(batch_x).reshape(-1, 1)\n","      loss = criterion(pred_y, batch_y)\n","      loss.backward()\n","      optimizer.step()\n","      \n","    with torch.no_grad():\n","      total_loss = 0\n","      accuracy = 0\n","      for batch_x, batch_y in dataloader:\n","        pred_y = model(batch_x).reshape(-1, 1)\n","        loss = criterion(pred_y, batch_y)\n","\n","        total_loss += float(loss)/len(dataloader)\n","        equals = (pred_y==batch_y)\n","        accuracy += torch.mean(equals.type(torch.FloatTensor))\n","      if epoch % 100 == 0: \n","        print(f'Training loss: {total_loss}, accuracy:{accuracy/len(dataloader)}')\n","train_data = pd.read_csv('train.csv')\n","preprocessed = preprocess_data(train_data)\n","train_data_y = np.array([preprocessed['Close Price'][i] for i in range(NUM_FETCH, len(preprocessed))])\n","train_data_x = preprocess_x(preprocessed, NUM_FETCH)\n","dataset = StockDataset(train_data_x, train_data_y)\n","dataloader = DataLoader(\n","    dataset,\n","    batch_size=NUM_BATCH,\n","    shuffle=True,\n","    collate_fn=collate_fn\n",")\n","\n","print(\"======Logistic Regression======\")\n","logistic_regression = LogisticRegression(NUM_FETCH)\n","criterion = nn.MSELoss()\n","optimizer = optim.SGD(logistic_regression.parameters(), lr=1e-3)\n","train(logistic_regression, criterion, optimizer)\n","\n","print(\"======Neural Network======\")\n","\n","neural_network = NeuralNetwork(NUM_FETCH)\n","criterion = nn.MSELoss()\n","optimizer = optim.SGD(neural_network.parameters(), lr=1e-3)\n","train(neural_network, criterion, optimizer)\n","\n","print(\"========SVM===============\")\n","svm = SVM(NUM_FETCH)\n","criterion = nn.MSELoss()\n","optimizer = optim.SGD(svm.parameters(), lr=1e-4)\n","train(svm, criterion, optimizer)\n"],"execution_count":231,"outputs":[{"output_type":"stream","text":["======Logistic Regression======\n","Epoch 0==========================\n","Training loss: 0.5221238968382895, accuracy:0.47787612676620483\n","Epoch 100==========================\n","Training loss: 0.5221238956514712, accuracy:0.47787612676620483\n","Epoch 200==========================\n","Training loss: 0.5222222248537354, accuracy:0.47777771949768066\n","Epoch 300==========================\n","Training loss: 0.5221730602526032, accuracy:0.47782689332962036\n","Epoch 400==========================\n","Training loss: 0.5219764018480759, accuracy:0.47802355885505676\n","======Neural Network======\n","Epoch 0==========================\n","Training loss: 0.4533431680329083, accuracy:0.5466567277908325\n","Epoch 100==========================\n","Training loss: 0.4534906586714553, accuracy:0.5465093851089478\n","Epoch 200==========================\n","Training loss: 0.45363815273858843, accuracy:0.5463617444038391\n","Epoch 300==========================\n","Training loss: 0.45339233223843395, accuracy:0.5466075539588928\n","Epoch 400==========================\n","Training loss: 0.4535398240637993, accuracy:0.5464602112770081\n","========SVM===============\n","Epoch 0==========================\n","Training loss: 0.5464110150273921, accuracy:0.45358893275260925\n","Epoch 100==========================\n","Training loss: 0.5466568357912842, accuracy:0.4533431828022003\n","Epoch 200==========================\n","Training loss: 0.5465585043472527, accuracy:0.45344141125679016\n","Epoch 300==========================\n","Training loss: 0.5466076710582836, accuracy:0.45339229702949524\n","Epoch 400==========================\n","Training loss: 0.5463618493713109, accuracy:0.4536382257938385\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NNT3VP3jgK8e","colab_type":"code","outputId":"d79d2c58-8e25-4251-d1fe-ff1443e7ce9a","executionInfo":{"status":"ok","timestamp":1590507623330,"user_tz":-480,"elapsed":789,"user":{"displayName":"F74056132洪培軒","photoUrl":"","userId":"18180719323566537567"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["test_data = pd.read_csv('test.csv')\n","preprocessed = preprocess_data(test_data)\n","test_data_y = np.array([preprocessed['Close Price'][i] for i in range(NUM_FETCH, len(preprocessed))])\n","test_data_x = preprocess_x(preprocessed, NUM_FETCH)\n","\n","correct = torch.tensor(test_data_y)>0\n","logistic_regression.eval()\n","predict = (logistic_regression(torch.tensor(test_data_x).float())).reshape(-1)\n","size = len(correct)\n","correct = (correct == predict).sum().item()\n","print(correct, correct/size)\n","\n","correct = torch.tensor(test_data_y)>0\n","neural_network.eval()\n","predict = (neural_network(torch.tensor(test_data_x).float())).reshape(-1)\n","correct = (correct == predict).sum().item()\n","print(correct, correct/size)\n","\n","correct = torch.tensor(test_data_y)>0\n","svm.eval()\n","predict = (svm(torch.tensor(test_data_x).float())).reshape(-1)\n","correct = (correct == predict).sum().item()\n","print(correct, correct/size)\n","\n","print(size)"],"execution_count":224,"outputs":[{"output_type":"stream","text":["126 0.5121951219512195\n","126 0.5121951219512195\n","120 0.4878048780487805\n","246\n"],"name":"stdout"}]}]}